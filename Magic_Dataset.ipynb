{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitarray import bitarray\n",
    "import random\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv('magic04.data', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1       2       3       4         5        6        7  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
       "\n",
       "         8         9 10  \n",
       "0  40.0920   81.8828  g  \n",
       "1   6.3609  205.2610  g  \n",
       "2  76.9600  256.7880  g  \n",
       "3  10.4490  116.7370  g  \n",
       "4   4.6480  356.4620  g  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.7967, 16.0021, 2.6449, 0.3918, 0.1982, 27.7004, 22.011,\n",
       "        -8.2027, 40.092, 81.8828],\n",
       "       [31.6036, 11.7235, 2.5185, 0.5303, 0.3773, 26.2722, 23.8238,\n",
       "        -9.9574, 6.3609, 205.261],\n",
       "       [162.05200000000002, 136.031, 4.0612, 0.0374, 0.0187, 116.741,\n",
       "        -64.858, -45.216, 76.96, 256.788],\n",
       "       [23.8172, 9.5728, 2.3385, 0.6147, 0.3922, 27.2107, -6.4633,\n",
       "        -7.1513, 10.449000000000002, 116.73700000000001],\n",
       "       [75.1362, 30.9205, 3.1611, 0.3168, 0.1832, -5.5277, 28.5525,\n",
       "        21.8393, 4.648, 356.462]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data.values[:,:-1])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "y = np.array(data.values[:,-1])\n",
    "y[y=='g']=0\n",
    "y[y=='h']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "[[-0.57722602 -0.33680419 -0.38113037 ... -0.40584194  0.47681587\n",
      "  -1.49786555]\n",
      " [-0.51096889 -0.57002666 -0.64859479 ... -0.49009359 -0.81541816\n",
      "   0.15312459]\n",
      " [ 2.56827756  6.20585836  2.61578306 ... -2.18302986  1.88922413\n",
      "   0.84263513]\n",
      " ...\n",
      " [ 0.52392318  1.38177927  1.31887687 ... -0.4665087   0.10163583\n",
      "   0.83900338]\n",
      " [ 1.58775746  2.98278123  2.47337518 ... -3.07720555  2.18525981\n",
      "   2.87032093]\n",
      " [ 3.16145936  1.67999288  0.81314905 ...  1.49930076  0.96101431\n",
      "   1.05044239]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=X[6166:19020]\n",
    "x_test=X[0:6166]\n",
    "np.random.shuffle(x_test)\n",
    "y_train=y[6166:19020]\n",
    "y_test=y[0:6166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_values = []\n",
    "size_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kraska Hash Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kraska_Hash_BloomFilter:\n",
    "    \n",
    "    def __init__(self, size, model): #hash count is 1\n",
    "        self.size = size\n",
    "      #  self.hash_count = hash_count\n",
    "        self.bit_array = bitarray(size)\n",
    "        self.bit_array.setall(0)\n",
    "        self.model=model #classifier model associated as hash function\n",
    "        \n",
    "    def add(self, num):\n",
    "        #for seed in range(1,self.hash_count+1):\n",
    "            #result = mmh3.hash(str(num), seed) % self.size\n",
    "        result=math.floor(model.predict(num)[0]*(self.size-1))    \n",
    "        self.bit_array[result] = 1\n",
    "            \n",
    "    def lookup(self, num):\n",
    "        #for seed in range(1,self.hash_count+1):\n",
    "            #result = mmh3.hash(str(num), seed) % self.size\n",
    "        result=math.floor(self.model.predict(num)[0]*(self.size-1))    \n",
    "        if self.bit_array[result] == 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def add_init(self,x_train,y_train):\n",
    "        pred = self.model.predict(x_train)\n",
    "        for i in range(len(pred)):\n",
    "            if(y_train[i]==1):\n",
    "                result = math.floor(pred[i][0]*(self.size-1))\n",
    "                self.bit_array[result] = 1\n",
    "\n",
    "    def predict(self,x):\n",
    "        initpred = self.model.predict(x)\n",
    "        indexes = []\n",
    "        for i in range(len(initpred)):\n",
    "            indexes += [math.floor(initpred[i][0]*(self.size-1))]\n",
    "        pred = []\n",
    "        for i in indexes:\n",
    "            pred += [self.bit_array[i]]\n",
    "        return np.array(pred)\n",
    "\n",
    "#adds ratio r of an array of random integers of size n to bloom filter bf(input : bf,size,ratio; output: data array)\n",
    "def addrandom(bf,n,r):\n",
    "    data=np.empty(n,dtype=int)\n",
    "    for i in range(0,n):\n",
    "        data[i]=random.randint(0, 100000000)\n",
    "    for j in range(0,int(n*r)):\n",
    "        bf.add(data[j])\n",
    "    return data\n",
    "\n",
    "#(Input:bloom filter,number array,ratio of positives; Output:(-1) for false negative, otherwise fpr)\n",
    "def fpr_kraska_hash(bf,x_test,y_test):\n",
    "    pred = bf.predict(x_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,pred).ravel() \n",
    "    return fp/(fp+tn)\n",
    "\n",
    "\n",
    "#(Input:bloom filter size, total random numbers, ratio of number inserted; Output:efficient number of hash functions)\n",
    "def eff_k(m,n,r):\n",
    "    k=int(m/(int(n*r))*math.log(2))\n",
    "    if(k==0):\n",
    "        return 1\n",
    "    return k\n",
    "\n",
    "#(Input:size of bloom filter, number of hash functions, total numbers, ratio of numbers inserted; Output: fpr)\n",
    "def find_fpr(m,model,n,r):\n",
    "    bf=Kraska_Hash_BloomFilter(model,m)\n",
    "    data=addrandom(bf,n,r)\n",
    "    return fpr(bf,data,r)\n",
    "\n",
    "#(Input:size of bloom filter, total numbers, ratio of numbers inserted; Output: prints inputs and fpr)\n",
    "def outputs(m,n,r):\n",
    "    find_fpr(m,model,n,r)\n",
    "    #print(\"For m=%d, k=%d, n=%d, r=%.3f: fpr=%.3f\"%(m,k,n,r,find_fpr(m,k,n,r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_points_Kraska(x_train,y_train,x_test,y_test,init_size,diff,num,epochs,fpr_values,size_values):\n",
    "    batch_size = len(x_train)\n",
    "    input_dim = x_train.shape[1]\n",
    "    additional_metrics = ['acc']\n",
    "    loss_function = BinaryCrossentropy()\n",
    "    optimizer = Adam()\n",
    "    verbosity_mode = 0\n",
    "    for i in range(0,num):\n",
    "        layer_size = init_size + (diff*i)\n",
    "        number_of_epochs = epochs\n",
    "        model = Sequential()\n",
    "        model.add(Dense(layer_size,input_dim=input_dim,activation='relu'))\n",
    "        model.add(Dense(1,activation='sigmoid'))\n",
    "        model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)\n",
    "        history = model.fit(x_train, y_train, batch_size = batch_size, epochs=number_of_epochs, verbose=verbosity_mode)\n",
    "\n",
    "        print(\"Number of nodes: %d\" %(init_size + (diff*i)))\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.show()\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.show()\n",
    "\n",
    "        model.save('model_test.h5')\n",
    "        model_size = os.stat('model_test.h5').st_size\n",
    "\n",
    "        m = (8*model_size)//100\n",
    "        net_size = 1.01*model_size/1024\n",
    "\n",
    "        bf=Kraska_Hash_BloomFilter(m,model)\n",
    "        bf.add_init(x_train,y_train)\n",
    "        fpr = fpr_kraska_hash(bf,x_test,y_test)\n",
    "\n",
    "        print(\"Size: %f KB - FPR: %f \\n\\n\\n\" % (net_size,fpr))\n",
    "        fpr_values += [fpr]\n",
    "        size_values += [net_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_points_Kraska(x_train,y_train,x_test,y_test,1,1,20,20000,fpr_values,size_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(size_values,fpr_values)\n",
    "plt.title('FPRs')\n",
    "plt.xlabel('Size(in KBs)')\n",
    "plt.ylabel('FPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection_BloomFilter:\n",
    "    def __init__(self, size, hash_count, dim):\n",
    "        vectors = np.random.normal(0,1,size=(hash_count,dim)) #random vectors(each row) from normal distribution, not unit vectors\n",
    "        i=0\n",
    "        while(i<hash_count):\n",
    "            if(vectors[i][0]<0):\n",
    "               # print(\"initial v\", vectors[i])\n",
    "                vectors[i]=np.random.normal(0,1,size=(1,dim))\n",
    "                #print(\"changed v\", vectors[i])\n",
    "            else: i=i+1\n",
    "       # print(vectors)   \n",
    "        self.unit_vectors = np.transpose(vectors/np.sqrt(np.transpose([np.sum(np.multiply(vectors,vectors),1)]))) #Matrix where each column is a unit vector, used as hash\n",
    "        self.size = size\n",
    "        self.hash_count = hash_count\n",
    "        self.bit_array = bitarray(size)\n",
    "        self.bit_array.setall(0)\n",
    "\n",
    "    def give_hash_values(self,X):\n",
    "        projections = np.dot(X,self.unit_vectors) #Projections of datapoints on unit vectors\n",
    "        norm_proj = 1/(1+np.exp(-projections)) #Sigmoid on each value so that they are in the range (0,1)\n",
    "        hash_values = (norm_proj*self.size).astype(int) #All values are integers in the range [0,size-1]\n",
    "        return hash_values #Each row contains hash values of that datapoint\n",
    "\n",
    "    def add(self,x):\n",
    "        hash_values = self.give_hash_values(x)\n",
    "        for i in hash_values:\n",
    "            self.bit_array[i] = 1\n",
    "        \n",
    "    def bulk_add(self, X):\n",
    "        hash_values = self.give_hash_values(X)\n",
    "        for i in hash_values:\n",
    "            for j in i:\n",
    "                self.bit_array[j] = 1\n",
    "            \n",
    "    def lookup(self, x):\n",
    "        hash_values = self.give_hash_values(x)\n",
    "        for i in hash_values:\n",
    "            if(self.bit_array[i]==0):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    \n",
    "#(Input:bloom filter,normalized positive data,normalized negative data; Output:(-1) for false negative, otherwise fpr)\n",
    "def find_fpr(bf,x_pos,x_neg):\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    pos_hash_values = bf.give_hash_values(x_pos)\n",
    "    neg_hash_values = bf.give_hash_values(x_neg)\n",
    "    for i in pos_hash_values:\n",
    "        for j in i:\n",
    "            if(bf.bit_array[j]==0):\n",
    "                return -1\n",
    "    for i in neg_hash_values:\n",
    "        flag = 0\n",
    "        for j in i:\n",
    "            if(bf.bit_array[j]==0):\n",
    "                tn += 1 \n",
    "                flag = 1           \n",
    "                break\n",
    "        if(flag==0):\n",
    "            fp += 1\n",
    "    return fp/(fp+tn)\n",
    "\n",
    "def find_fpr2(bf,x_neg):\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    neg_hash_values = bf.give_hash_values(x_neg)\n",
    "    for i in neg_hash_values:\n",
    "        flag = 0\n",
    "        for j in i:\n",
    "            if(bf.bit_array[j]==0):\n",
    "                tn += 1 \n",
    "                flag = 1           \n",
    "                break\n",
    "        if(flag==0):\n",
    "            fp += 1\n",
    "    return fp/(fp+tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_points_Projection(x_train,x_test,y_train,init_size,diff,num,epochs,fpr_values,size_values):\n",
    "    input_dim = x_train.shape[1]\n",
    "    n = sum(y_train)\n",
    "    x_pos = x_train[(y_train==1).reshape(-1)]\n",
    "    x_neg = x_train[(y_train==0).reshape(-1)]\n",
    "    for i in range(0,num):\n",
    "        m = init_size + i*diff\n",
    "        k = eff_k(m,n,1)\n",
    "        fpr = 1\n",
    "        for j in range(0,epochs):\n",
    "            bf = Projection_BloomFilter(m,k,input_dim)\n",
    "            bf.bulk_add(x_pos)\n",
    "            temp = find_fpr(bf,x_pos,x_neg)\n",
    "            if(fpr>temp):\n",
    "                fpr = temp\n",
    "                tempbf=bf\n",
    "        fpr_test=find_fpr2(tempbf,x_test)\n",
    "        print(\"Size: %d Bits - FPR: %f \\n\\n\\n\" % (m,fpr_test))\n",
    "        fpr_values += [fpr_test]\n",
    "        size_values += [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_values = []\n",
    "size_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_points_Projection(x_train,x_test,y_train,5,10,200,100,fpr_values,size_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(size_values,fpr_values)\n",
    "plt.title('FPRs')\n",
    "plt.xlabel('Size(in Bits)')\n",
    "plt.ylabel('FPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Bloom Filter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_fpr(m,n):\n",
    "    k = eff_k(m,n,1)\n",
    "    return (1-(1-(1/m))**(n*k))**k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(y_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sum(y_train)\n",
    "y_ideal = [ideal_fpr(x,n) for x in size_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(size_values,y_ideal)\n",
    "plt.title('FPRs')\n",
    "plt.xlabel('Size(in Bits)')\n",
    "plt.ylabel('FPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPR Comparison between Projection Model and Normal Bloom Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(size_values,y_ideal,color='red')\n",
    "plt.plot(size_values,fpr_values,color='green')\n",
    "plt.title('FPRs')\n",
    "plt.xlabel('Size(in Bits)')\n",
    "plt.ylabel('FPR')\n",
    "plt.show()\n",
    "# Red- Normal Bloom Filter\n",
    "# Green- Projection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
