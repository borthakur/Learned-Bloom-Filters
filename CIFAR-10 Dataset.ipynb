{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitarray import bitarray\n",
    "import random\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.datasets as skds\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = skds.fetch_openml(\"cifar_10\", return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 3072)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=images\n",
    "X = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[labels=='4']=0\n",
    "labels[labels=='6']=0\n",
    "labels[labels=='8']=0\n",
    "labels[labels=='9']=0\n",
    "labels[labels=='0']=0\n",
    "labels[labels=='2']=1\n",
    "labels[labels=='3']=1\n",
    "labels[labels=='5']=1\n",
    "labels[labels=='7']=1\n",
    "labels[labels=='1']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_neg=X[labels==0]\n",
    "x_pos=X[labels==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(x_neg)\n",
    "x_test=x_neg[0:15000]\n",
    "x_train=x_neg[15000:30000]\n",
    "x_train=np.concatenate((x_train,x_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.concatenate((np.zeros(15000),np.ones(30000)))\n",
    "y_test=np.zeros(15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kraska Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kraska_Hash_BloomFilter:\n",
    "    \n",
    "    def __init__(self, size, model): #hash count is 1\n",
    "        self.size = size\n",
    "      #  self.hash_count = hash_count\n",
    "        self.bit_array = bitarray(size)\n",
    "        self.bit_array.setall(0)\n",
    "        self.model=model #classifier model associated as hash function\n",
    "        \n",
    "    def add(self, num):\n",
    "        #for seed in range(1,self.hash_count+1):\n",
    "            #result = mmh3.hash(str(num), seed) % self.size\n",
    "        result=math.floor(model.predict(num)[0]*(self.size-1))    \n",
    "        self.bit_array[result] = 1\n",
    "            \n",
    "    def lookup(self, num):\n",
    "        #for seed in range(1,self.hash_count+1):\n",
    "            #result = mmh3.hash(str(num), seed) % self.size\n",
    "        result=math.floor(self.model.predict(num)[0]*(self.size-1))    \n",
    "        if self.bit_array[result] == 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def add_init(self,x_train,y_train):\n",
    "        pred = self.model.predict(x_train)\n",
    "        for i in range(len(pred)):\n",
    "            if(y_train[i]==1):\n",
    "                result = math.floor(pred[i][0]*(self.size-1))\n",
    "                self.bit_array[result] = 1\n",
    "\n",
    "    def predict(self,x):\n",
    "        initpred = self.model.predict(x)\n",
    "        indexes = []\n",
    "        for i in range(len(initpred)):\n",
    "            indexes += [math.floor(initpred[i][0]*(self.size-1))]\n",
    "        pred = []\n",
    "        for i in indexes:\n",
    "            pred += [self.bit_array[i]]\n",
    "        return np.array(pred)\n",
    "\n",
    "#adds ratio r of an array of random integers of size n to bloom filter bf(input : bf,size,ratio; output: data array)\n",
    "def addrandom(bf,n,r):\n",
    "    data=np.empty(n,dtype=int)\n",
    "    for i in range(0,n):\n",
    "        data[i]=random.randint(0, 100000000)\n",
    "    for j in range(0,int(n*r)):\n",
    "        bf.add(data[j])\n",
    "    return data\n",
    "\n",
    "#(Input:bloom filter,number array,ratio of positives; Output:(-1) for false negative, otherwise fpr)\n",
    "def fpr_kraska_hash(bf,x_test,y_test):\n",
    "    pred = bf.predict(x_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,pred,labels=[False,True]).ravel() \n",
    "    return fp/(fp+tn)\n",
    "\n",
    "#(Input:bloom filter size, total random numbers, ratio of number inserted; Output:efficient number of hash functions)\n",
    "def eff_k(m,n,r):\n",
    "    k=int(m/(int(n*r))*math.log(2))\n",
    "    if(k==0):\n",
    "        return 1\n",
    "    return k\n",
    "\n",
    "#(Input:size of bloom filter, number of hash functions, total numbers, ratio of numbers inserted; Output: fpr)\n",
    "def find_fpr(m,model,n,r):\n",
    "    bf=Kraska_Hash_BloomFilter(model,m)\n",
    "    data=addrandom(bf,n,r)\n",
    "    return fpr(bf,data,r)\n",
    "\n",
    "#(Input:size of bloom filter, total numbers, ratio of numbers inserted; Output: prints inputs and fpr)\n",
    "def outputs(m,n,r):\n",
    "    find_fpr(m,model,n,r)\n",
    "    #print(\"For m=%d, k=%d, n=%d, r=%.3f: fpr=%.3f\"%(m,k,n,r,find_fpr(m,k,n,r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_points_Kraska(x_train,y_train,x_test,y_test,init_size,diff,num,epochs,fpr_values_kraska,size_values_kraska):\n",
    "    batch_size = len(x_train)\n",
    "    input_dim = x_train.shape[1]\n",
    "    additional_metrics = ['acc']\n",
    "    loss_function = BinaryCrossentropy()\n",
    "    optimizer = Adam()\n",
    "    verbosity_mode = 0\n",
    "    for i in range(0,num):\n",
    "        layer_size = init_size + (diff*i)\n",
    "        number_of_epochs = epochs\n",
    "        model = Sequential()\n",
    "        model.add(Dense(layer_size,input_dim=input_dim,activation='relu'))\n",
    "        model.add(Dense(1,activation='sigmoid'))\n",
    "        model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)\n",
    "        history = model.fit(x_train, y_train, batch_size = batch_size, epochs=number_of_epochs, verbose=verbosity_mode)\n",
    "\n",
    "        print(\"Number of nodes: %d\" %(init_size + (diff*i)))\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.show()\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.show()\n",
    "\n",
    "        model_size = ((input_dim+1)*layer_size + (layer_size+1))*32\n",
    "\n",
    "        m = int(model_size/10) + 1\n",
    "        net_size = model_size + m\n",
    "\n",
    "        bf=Kraska_Hash_BloomFilter(m,model)\n",
    "        bf.add_init(x_train,y_train)\n",
    "        fpr = fpr_kraska_hash(bf,x_test,y_test)\n",
    "\n",
    "        print(\"Size: %f bits - FPR: %f \\n\\n\\n\" % (net_size,fpr))\n",
    "        fpr_values_kraska += [fpr]\n",
    "        size_values_kraska += [net_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~ Iteration 1 ~~~~~~~~ \n",
      "\n",
      "WARNING:tensorflow:From /Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/aditijain/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c33cc8ddc572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~~~~~~~~ Iteration %d ~~~~~~~~ \\n\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mget_data_points_Kraska\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfpr_values_kraska\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_values_kraska\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-ea28c54b8edb>\u001b[0m in \u001b[0;36mget_data_points_Kraska\u001b[0;34m(x_train, y_train, x_test, y_test, init_size, diff, num, epochs, fpr_values_kraska, size_values_kraska)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of nodes: %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3275\u001b[0m         \u001b[0mtensor_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m         array_vals.append(np.asarray(value,\n\u001b[0;32m-> 3277\u001b[0;31m                                      dtype=tensor_type.as_numpy_dtype))\n\u001b[0m\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_of_iterations = 3 #Increase to make graph smoother\n",
    "\n",
    "fpr_values_kraska = []\n",
    "size_values_kraska = []\n",
    "\n",
    "for i in range(0,num_of_iterations):\n",
    "    print(\"~~~~~~~~ Iteration %d ~~~~~~~~ \\n\" %(i+1))\n",
    "    get_data_points_Kraska(x_train,y_train,x_test,y_test,15,2,5,3000,fpr_values_kraska,size_values_kraska)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)},style=\"whitegrid\")\n",
    "sns.lineplot(x=size_values_kraska, y=fpr_values_kraska, err_style=\"band\",label = \"Kraska\",linewidth = 1.5,marker=\"o\")\n",
    "plt.title('FPRs')\n",
    "plt.xlabel(\"Size\", fontsize = 15)\n",
    "plt.ylabel(\"FPR\", fontsize = 15)\n",
    "#plt.figure(figsize = (5000,5000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection_BloomFilter:\n",
    "    def __init__(self, size, hash_count, dim):\n",
    "        vectors = np.random.normal(0,1,size=(hash_count,dim)) #random vectors(each row) from normal distribution, not unit vectors       \n",
    "        self.unit_vectors = np.transpose(vectors/np.sqrt(np.transpose([np.sum(np.multiply(vectors,vectors),1)]))) #Matrix where each column is a unit vector, used as hash\n",
    "        self.size = size\n",
    "        self.hash_count = hash_count\n",
    "        self.bit_array = bitarray(size)\n",
    "        self.bit_array.setall(0)\n",
    "\n",
    "    def give_hash_values(self,X):\n",
    "        projections = np.dot(X,self.unit_vectors) #Projections of datapoints on unit vectors\n",
    "        norm_proj = 1/(1+np.exp(-projections)) #Sigmoid on each value so that they are in the range (0,1)\n",
    "        hash_values = (norm_proj*(self.size-1)).astype(int) #All values are integers in the range [0,size-1]\n",
    "        return hash_values                        #Each row contains hash values of that datapoint\n",
    "\n",
    "    def add(self,x):\n",
    "        hash_values = self.give_hash_values(x)\n",
    "        for i in hash_values:\n",
    "            self.bit_array[i] = 1\n",
    "        \n",
    "    def bulk_add(self, X):\n",
    "        hash_values = self.give_hash_values(X)\n",
    "        for i in hash_values:\n",
    "            for j in i:\n",
    "                self.bit_array[j] = 1\n",
    "            \n",
    "    def lookup(self, x):\n",
    "        hash_values = self.give_hash_values(x)\n",
    "        for i in hash_values:\n",
    "            if(self.bit_array[i]==0):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    \n",
    "#(Input:bloom filter,normalized positive data,normalized negative data; Output:(-1) for false negative, otherwise fpr)\n",
    "def find_fpr(bf,x_pos,x_neg):\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    pos_hash_values = bf.give_hash_values(x_pos)\n",
    "    neg_hash_values = bf.give_hash_values(x_neg)\n",
    "    for i in pos_hash_values:\n",
    "        for j in i:\n",
    "            if(bf.bit_array[j]==0):\n",
    "                return -1\n",
    "    for i in neg_hash_values:\n",
    "        flag = 0\n",
    "        for j in i:\n",
    "            if(bf.bit_array[j]==0):\n",
    "                tn += 1 \n",
    "                flag = 1           \n",
    "                break\n",
    "        if(flag==0):\n",
    "            fp += 1\n",
    "    return fp/(fp+tn)\n",
    "\n",
    "def find_fpr2(bf,x_neg):\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    neg_hash_values = bf.give_hash_values(x_neg)\n",
    "    for i in neg_hash_values:\n",
    "        flag = 0\n",
    "        for j in i:\n",
    "            if(bf.bit_array[j]==0):\n",
    "                tn += 1 \n",
    "                flag = 1           \n",
    "                break\n",
    "        if(flag==0):\n",
    "            fp += 1\n",
    "    return fp/(fp+tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_points_Projection(x_train,x_test,y_train,init_size,diff,num,epochs,fpr_values,size_values):\n",
    "    input_dim = x_train.shape[1]\n",
    "    n = sum(y_train)\n",
    "    x_pos = x_train[(y_train==1).reshape(-1)]\n",
    "    print(x_pos.shape)\n",
    "    x_neg = x_train[(y_train==0).reshape(-1)]\n",
    "    for i in range(0,num):\n",
    "        m = init_size + i*diff\n",
    "        k = eff_k(m,n,1)\n",
    "        fpr = 1\n",
    "        tempbf = Projection_BloomFilter(m,k,input_dim)\n",
    "        for j in range(0,epochs):\n",
    "            bf = Projection_BloomFilter(m,k,input_dim)\n",
    "            bf.bulk_add(x_pos)\n",
    "            temp = find_fpr(bf,x_pos,x_neg)\n",
    "            if(fpr>=temp):\n",
    "                fpr = temp\n",
    "                tempbf=bf\n",
    "        fpr_test=find_fpr2(tempbf,x_test)\n",
    "        print(\"Size: %d Bits - FPR: %f \\n\\n\\n\" % (m,fpr_test))\n",
    "        fpr_values += [fpr_test]\n",
    "        size_values += [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~ Iteration 1 ~~~~~~~~ \n",
      "\n",
      "(30000, 3072)\n",
      "Size: 90000 Bits - FPR: 0.254733 \n",
      "\n",
      "\n",
      "\n",
      "Size: 92000 Bits - FPR: 0.226933 \n",
      "\n",
      "\n",
      "\n",
      "Size: 94000 Bits - FPR: 0.216867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 96000 Bits - FPR: 0.224600 \n",
      "\n",
      "\n",
      "\n",
      "Size: 98000 Bits - FPR: 0.213667 \n",
      "\n",
      "\n",
      "\n",
      "Size: 100000 Bits - FPR: 0.231400 \n",
      "\n",
      "\n",
      "\n",
      "Size: 102000 Bits - FPR: 0.219600 \n",
      "\n",
      "\n",
      "\n",
      "Size: 104000 Bits - FPR: 0.221933 \n",
      "\n",
      "\n",
      "\n",
      "Size: 106000 Bits - FPR: 0.208733 \n",
      "\n",
      "\n",
      "\n",
      "Size: 108000 Bits - FPR: 0.186333 \n",
      "\n",
      "\n",
      "\n",
      "Size: 110000 Bits - FPR: 0.195000 \n",
      "\n",
      "\n",
      "\n",
      "Size: 112000 Bits - FPR: 0.176267 \n",
      "\n",
      "\n",
      "\n",
      "Size: 114000 Bits - FPR: 0.169600 \n",
      "\n",
      "\n",
      "\n",
      "Size: 116000 Bits - FPR: 0.179400 \n",
      "\n",
      "\n",
      "\n",
      "Size: 118000 Bits - FPR: 0.174067 \n",
      "\n",
      "\n",
      "\n",
      "Size: 120000 Bits - FPR: 0.161067 \n",
      "\n",
      "\n",
      "\n",
      "Size: 122000 Bits - FPR: 0.168133 \n",
      "\n",
      "\n",
      "\n",
      "Size: 124000 Bits - FPR: 0.150600 \n",
      "\n",
      "\n",
      "\n",
      "Size: 126000 Bits - FPR: 0.152200 \n",
      "\n",
      "\n",
      "\n",
      "Size: 128000 Bits - FPR: 0.143267 \n",
      "\n",
      "\n",
      "\n",
      "Size: 130000 Bits - FPR: 0.143733 \n",
      "\n",
      "\n",
      "\n",
      "Size: 132000 Bits - FPR: 0.132000 \n",
      "\n",
      "\n",
      "\n",
      "Size: 134000 Bits - FPR: 0.141467 \n",
      "\n",
      "\n",
      "\n",
      "Size: 136000 Bits - FPR: 0.128867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 138000 Bits - FPR: 0.119200 \n",
      "\n",
      "\n",
      "\n",
      "Size: 140000 Bits - FPR: 0.119933 \n",
      "\n",
      "\n",
      "\n",
      "Size: 142000 Bits - FPR: 0.110400 \n",
      "\n",
      "\n",
      "\n",
      "Size: 144000 Bits - FPR: 0.119867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 146000 Bits - FPR: 0.110067 \n",
      "\n",
      "\n",
      "\n",
      "Size: 148000 Bits - FPR: 0.112200 \n",
      "\n",
      "\n",
      "\n",
      "Size: 150000 Bits - FPR: 0.091067 \n",
      "\n",
      "\n",
      "\n",
      "Size: 152000 Bits - FPR: 0.102133 \n",
      "\n",
      "\n",
      "\n",
      "Size: 154000 Bits - FPR: 0.095667 \n",
      "\n",
      "\n",
      "\n",
      "Size: 156000 Bits - FPR: 0.104267 \n",
      "\n",
      "\n",
      "\n",
      "Size: 158000 Bits - FPR: 0.095133 \n",
      "\n",
      "\n",
      "\n",
      "Size: 160000 Bits - FPR: 0.094867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 162000 Bits - FPR: 0.083200 \n",
      "\n",
      "\n",
      "\n",
      "Size: 164000 Bits - FPR: 0.091933 \n",
      "\n",
      "\n",
      "\n",
      "Size: 166000 Bits - FPR: 0.086733 \n",
      "\n",
      "\n",
      "\n",
      "Size: 168000 Bits - FPR: 0.088867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 170000 Bits - FPR: 0.090333 \n",
      "\n",
      "\n",
      "\n",
      "Size: 172000 Bits - FPR: 0.086000 \n",
      "\n",
      "\n",
      "\n",
      "Size: 174000 Bits - FPR: 0.069867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 176000 Bits - FPR: 0.080133 \n",
      "\n",
      "\n",
      "\n",
      "Size: 178000 Bits - FPR: 0.074733 \n",
      "\n",
      "\n",
      "\n",
      "Size: 180000 Bits - FPR: 0.068267 \n",
      "\n",
      "\n",
      "\n",
      "Size: 182000 Bits - FPR: 0.077333 \n",
      "\n",
      "\n",
      "\n",
      "Size: 184000 Bits - FPR: 0.066867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 186000 Bits - FPR: 0.071200 \n",
      "\n",
      "\n",
      "\n",
      "Size: 188000 Bits - FPR: 0.070267 \n",
      "\n",
      "\n",
      "\n",
      "Size: 190000 Bits - FPR: 0.054867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 192000 Bits - FPR: 0.065533 \n",
      "\n",
      "\n",
      "\n",
      "Size: 194000 Bits - FPR: 0.051533 \n",
      "\n",
      "\n",
      "\n",
      "Size: 196000 Bits - FPR: 0.056333 \n",
      "\n",
      "\n",
      "\n",
      "Size: 198000 Bits - FPR: 0.053133 \n",
      "\n",
      "\n",
      "\n",
      "Size: 200000 Bits - FPR: 0.047400 \n",
      "\n",
      "\n",
      "\n",
      "Size: 202000 Bits - FPR: 0.057133 \n",
      "\n",
      "\n",
      "\n",
      "Size: 204000 Bits - FPR: 0.055133 \n",
      "\n",
      "\n",
      "\n",
      "Size: 206000 Bits - FPR: 0.058267 \n",
      "\n",
      "\n",
      "\n",
      "Size: 208000 Bits - FPR: 0.052467 \n",
      "\n",
      "\n",
      "\n",
      "Size: 210000 Bits - FPR: 0.048867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 212000 Bits - FPR: 0.055733 \n",
      "\n",
      "\n",
      "\n",
      "Size: 214000 Bits - FPR: 0.048867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 216000 Bits - FPR: 0.048200 \n",
      "\n",
      "\n",
      "\n",
      "Size: 218000 Bits - FPR: 0.045333 \n",
      "\n",
      "\n",
      "\n",
      "Size: 220000 Bits - FPR: 0.041133 \n",
      "\n",
      "\n",
      "\n",
      "Size: 222000 Bits - FPR: 0.039467 \n",
      "\n",
      "\n",
      "\n",
      "Size: 224000 Bits - FPR: 0.034800 \n",
      "\n",
      "\n",
      "\n",
      "Size: 226000 Bits - FPR: 0.040800 \n",
      "\n",
      "\n",
      "\n",
      "Size: 228000 Bits - FPR: 0.036333 \n",
      "\n",
      "\n",
      "\n",
      "Size: 230000 Bits - FPR: 0.037200 \n",
      "\n",
      "\n",
      "\n",
      "Size: 232000 Bits - FPR: 0.036067 \n",
      "\n",
      "\n",
      "\n",
      "Size: 234000 Bits - FPR: 0.036000 \n",
      "\n",
      "\n",
      "\n",
      "Size: 236000 Bits - FPR: 0.032667 \n",
      "\n",
      "\n",
      "\n",
      "Size: 238000 Bits - FPR: 0.032333 \n",
      "\n",
      "\n",
      "\n",
      "Size: 240000 Bits - FPR: 0.033933 \n",
      "\n",
      "\n",
      "\n",
      "Size: 242000 Bits - FPR: 0.030600 \n",
      "\n",
      "\n",
      "\n",
      "Size: 244000 Bits - FPR: 0.028000 \n",
      "\n",
      "\n",
      "\n",
      "Size: 246000 Bits - FPR: 0.036200 \n",
      "\n",
      "\n",
      "\n",
      "Size: 248000 Bits - FPR: 0.025800 \n",
      "\n",
      "\n",
      "\n",
      "Size: 250000 Bits - FPR: 0.033600 \n",
      "\n",
      "\n",
      "\n",
      "Size: 252000 Bits - FPR: 0.033000 \n",
      "\n",
      "\n",
      "\n",
      "Size: 254000 Bits - FPR: 0.026067 \n",
      "\n",
      "\n",
      "\n",
      "Size: 256000 Bits - FPR: 0.024200 \n",
      "\n",
      "\n",
      "\n",
      "Size: 258000 Bits - FPR: 0.030933 \n",
      "\n",
      "\n",
      "\n",
      "Size: 260000 Bits - FPR: 0.026933 \n",
      "\n",
      "\n",
      "\n",
      "Size: 262000 Bits - FPR: 0.022867 \n",
      "\n",
      "\n",
      "\n",
      "Size: 264000 Bits - FPR: 0.025000 \n",
      "\n",
      "\n",
      "\n",
      "Size: 266000 Bits - FPR: 0.023333 \n",
      "\n",
      "\n",
      "\n",
      "Size: 268000 Bits - FPR: 0.021533 \n",
      "\n",
      "\n",
      "\n",
      "Size: 270000 Bits - FPR: 0.027067 \n",
      "\n",
      "\n",
      "\n",
      "Size: 272000 Bits - FPR: 0.019333 \n",
      "\n",
      "\n",
      "\n",
      "Size: 274000 Bits - FPR: 0.022733 \n",
      "\n",
      "\n",
      "\n",
      "Size: 276000 Bits - FPR: 0.019933 \n",
      "\n",
      "\n",
      "\n",
      "Size: 278000 Bits - FPR: 0.019333 \n",
      "\n",
      "\n",
      "\n",
      "Size: 280000 Bits - FPR: 0.018733 \n",
      "\n",
      "\n",
      "\n",
      "Size: 282000 Bits - FPR: 0.017600 \n",
      "\n",
      "\n",
      "\n",
      "Size: 284000 Bits - FPR: 0.019800 \n",
      "\n",
      "\n",
      "\n",
      "Size: 286000 Bits - FPR: 0.019467 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_of_iterations = 1 #Increase to make graph smoother\n",
    "\n",
    "fpr_values = []\n",
    "size_values = []\n",
    "\n",
    "for i in range(0,num_of_iterations):\n",
    "    print(\"~~~~~~~~ Iteration %d ~~~~~~~~ \\n\" %(i+1))\n",
    "    get_data_points_Projection(x_train,x_test,y_train,90000,2000,100,100,fpr_values,size_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)},style=\"whitegrid\")\n",
    "sns.lineplot(x=size_values, y=fpr_values, err_style=\"band\",label = \"Projection\",linewidth = 1.5,color=\"g\")\n",
    "plt.title('FPRs')\n",
    "plt.xlabel(\"Size\", fontsize = 15)\n",
    "plt.ylabel(\"FPR\", fontsize = 15)\n",
    "#plt.figure(figsize = (5000,5000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Bloom Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_fpr(m,n):\n",
    "    k = eff_k(m,n,1)\n",
    "    return (1-(1-(1/m))**(n*k))**k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(y_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sum(y_train)\n",
    "y_ideal=[]\n",
    "for x in size_values:\n",
    "    y_ideal+=[float(ideal_fpr(x,n))]\n",
    "print(len(y_ideal))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)},style=\"whitegrid\")\n",
    "sns.lineplot(x=size_values, y=y_ideal, err_style=\"band\",label = \"Ideal\",linewidth = 1.5,color=\"r\")\n",
    "plt.title('FPRs')\n",
    "plt.xlabel(\"Size\", fontsize = 15)\n",
    "plt.ylabel(\"FPR\", fontsize = 15)\n",
    "#plt.figure(figsize = (5000,5000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # FPR Comparison between Projection Model and Normal Bloom Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)},style=\"whitegrid\")\n",
    "sns.lineplot(x=size_values, y=fpr_values, err_style=\"band\",label = \"Projection\",linewidth = 1.5,color=\"g\")\n",
    "sns.lineplot(x=size_values, y=y_ideal, err_style=\"band\",label = \"Ideal\",linewidth = 1.5,color=\"r\")\n",
    "plt.title('FPRs')\n",
    "plt.xlabel(\"Size\", fontsize = 15)\n",
    "plt.ylabel(\"FPR\", fontsize = 15)\n",
    "#plt.figure(figsize = (5000,5000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPR Comparison between all 3 models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_points_Projection2(x_train,x_test,y_train,epochs,fpr_values,size_values_kraska):\n",
    "    input_dim = x_train.shape[1]\n",
    "    n = sum(y_train)\n",
    "    x_pos = x_train[(y_train==1).reshape(-1)]\n",
    "    print(x_pos.shape)\n",
    "    x_neg = x_train[(y_train==0).reshape(-1)]\n",
    "    for i in size_values_kraska:\n",
    "        m = i\n",
    "        k = eff_k(m,n,1)\n",
    "        fpr = 1\n",
    "        tempbf = Projection_BloomFilter(m,k,input_dim)\n",
    "        for j in range(0,epochs):\n",
    "            bf = Projection_BloomFilter(m,k,input_dim)\n",
    "            bf.bulk_add(x_pos)\n",
    "            temp = find_fpr(bf,x_pos,x_neg)\n",
    "            if(fpr>temp):\n",
    "                fpr = temp\n",
    "                tempbf=bf\n",
    "        fpr_test=find_fpr2(tempbf,x_test)\n",
    "        print(\"Size: %d Bits - FPR: %f \\n\\n\\n\" % (m,fpr_test))\n",
    "        fpr_values += [fpr_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran only once instead of thrice as size_values_kraska already has triple length\n",
    "fpr_values_projection = []\n",
    "get_data_points_Projection2(x_train,x_test,y_train,100,fpr_values_projection,size_values_kraska)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sum(y_train)\n",
    "y_ideal_k=[]\n",
    "for x in size_values_kraska:\n",
    "    y_ideal_k+=[float(ideal_fpr(x,n))]\n",
    "print(len(y_ideal_k))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)},style=\"whitegrid\")\n",
    "sns.lineplot(x=size_values_kraska, y=fpr_values_kraska, err_style=\"band\",marker=\"o\",label = \"Kraska\",linestyle= \"--\",markersize=10)\n",
    "sns.lineplot(x=size_values_kraska, y=y_ideal_k, err_style=\"band\",marker='>',label = \"Ideal\",linestyle= \":\",markersize = 10)\n",
    "sns.lineplot(x=size_values_kraska, y=fpr_values_projection, err_style=\"band\",marker='<',label = \"Projection\",linestyle= \"-.\",markersize = 10)\n",
    "plt.title('FPRs')\n",
    "plt.xlabel(\"Size\", fontsize = 15)\n",
    "plt.ylabel(\"FPR\", fontsize = 15)\n",
    "#plt.figure(figsize = (5000,5000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
